
# default basic settings for UCAgent
lang: "zh"

# init commands to run at the start of the agent
init_cmds: []

# Model support: openai, anthropic, google_genai
model_type: openai

openai:
  model_name: "$(OPENAI_MODEL: <your_chat_model_name>)"
  openai_api_key: "$(OPENAI_API_KEY: [your_api_key])"
  openai_api_base: "$(OPENAI_API_BASE: http://<your_chat_model_url>/v1)"
  model_kwargs:
    stop: ["."]

# export ANTHROPIC_API_KEY="your-api-key"
anthropic:
  model: "$(ANTHROPIC_MODEL: claude-3-7-sonnet-20250219)"

# export GOOGLE_GENAI_API_KEY="your-api-key"
google_genai:
  model: "$(GOOGLE_GENAI_MODEL: gemini-2.5-pro)"

embed:
  model_name: "$(EMBED_MODEL: <your_embedding_model_name>)"
  openai_api_key: "$(EMBED_OPENAI_API_KEY: [your_api_key])"
  openai_api_base: "$(EMBED_OPENAI_API_BASE: http://<your_embedding_model_url>/v1)"
  dims: 4096

langfuse:
  enable: $(ENABLE_LANGFUSE, false)
  public_key: $(LANGFUSE_PUBLIC_KEY, <YOUR_LANGFUSE_PUBLIC_KEY>)
  secret_key: $(LANGFUSE_SECRET_KEY, <YOUR_LANGFUSE_SECRET_KEY>)
  base_url: $(LANGFUSE_URL, http://localhost:3000)

# This is the setting for conversation summary
# Adjust the max_tokens and max_summary_tokens according to your needs and model capabilities
# Reference doc: https://langchain-ai.lang.chat/langmem/reference/short_term/#langmem.short_term.SummarizationNode
# if use_uc_mode is false (summarization mode):
#   Param: max_tokens, suggested 50% of the model's context length
# if use_uc_mode is true (unity chip summarization and trim mode):
#   Param: max_tokens is not used
#   Param: max_summary_tokens, suggested 10% of the model's context length
conversation_summary:
  max_tokens: 51200    # default 50k tokens for 128k context model
  max_summary_tokens: 1024
  max_keep_msgs: 100   # max messages to keep in memory, older messages will be removed (not the messages to LLM)
  use_uc_mode: true    # default use uc mode to manage conversation history
  tail_keep_msgs: 10   # when use_uc_mode is true, keep the last N messages to the LLM no matter what

rate_limiter:
  enabled: false
  # The following settings are used when rate_limiter.enabled is true
  requests_per_second: 10    # default 10 req/s
  check_every_n_seconds: 0.1 # default 0.1s, wake up every 100 ms to check whether allowed to make a request
  max_bucket_size: 1         # default 1, controls the maximum burst size

template: unity_test

un_write_dirs:
  - "{DUT}"
  - "Guide_Doc"
write_dirs:
  - "{OUT}"

tools:
  RunTestCases:
    test_dir: "{OUT}/tests"
  ignore_tools: ["WorkDiff", "WorkCommit"] # List of tool names to ignore
  selected_tools: []     # List of tool names to enable, if empty, all tools are enabled except those in ignore_tools

# Tool call timeout
call_time_out: 300  # seconds

# TUI layout settings
tui:
  task_width: 84
  console_height: 13
  status_height: 7


hooks:
  continue: >
    You have not completed all the tasks yet. Please continue. Use the `Check` and `Complete` tools to determine whether you have finished the current stage's tasks.
    Please verify the results of the `Check` and `Complete` tool calls, and adjust your work based on the feedback until all `Check` and `Complete` calls are passed.
    If a timeout error occurs, please increase the timeout parameter and retry, or use the RunTestCases tool to identify any stuck test cases and fix them.

  cagent_init: >
    Please get your role information and basic guidance through tool `RoleInfo`, and then complete the task.
    Please make sure to use the tool `ReadTextFile` to read the file, so that UCAgent can know which files you have read.

  quit: "/quit"

  exit: "/exit"
